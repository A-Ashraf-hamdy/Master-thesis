{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9da377b4",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee9240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chardet\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt \n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "import plotly.colors as pc\n",
    "%matplotlib inline  \n",
    "import psutil\n",
    "from pathlib import Path\n",
    "#from Functions import *\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import psutil\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25469f50",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315ce25f",
   "metadata": {},
   "source": [
    "## Preparing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fab9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "# ARX\n",
    "ARX_train_heave_true=pd.read_csv('Results/ARX/Training and Validation/y_true_train_df_heave_nb2_nf7.csv')\n",
    "ARX_train_heave_pred=pd.read_csv('Results/ARX/Training and Validation/y_pred_train_df_heave_nb2_nf7.csv')\n",
    "\n",
    "ARX_val_heave_true=pd.read_csv('Results/ARX/Training and Validation/y_true_val_df_heave_nb2_nf7.csv')\n",
    "ARX_val_heave_pred=pd.read_csv('Results/ARX/Training and Validation/y_pred_val_df_heave_nb2_nf7.csv')\n",
    "\n",
    "ARX_train_pitch_true=pd.read_csv('Results/ARX/Training and Validation/y_true_train_df_pitch_nb2_nf7.csv')\n",
    "ARX_train_pitch_pred=pd.read_csv('Results/ARX/Training and Validation/y_pred_train_df_pitch_nb2_nf7.csv')\n",
    "\n",
    "ARX_val_pitch_true=pd.read_csv('Results/ARX/Training and Validation/y_true_val_df_pitch_nb2_nf7.csv')\n",
    "ARX_val_pitch_pred=pd.read_csv('Results/ARX/Training and Validation/y_pred_val_df_pitch_nb2_nf7.csv')\n",
    "\n",
    "ARX_train_pendulum_true=pd.read_csv('Results/ARX/Training and Validation/y_true_train_ARX_penddulum_nb4_nf2.csv')\n",
    "ARX_train_pendulum_pred=pd.read_csv('Results/ARX/Training and Validation/y_pred_train_df_ARX_penddulum_nb4_nf2.csv')\n",
    "\n",
    "ARX_val_pendulum_true=pd.read_csv('Results/ARX/Training and Validation/y_true_val_ARX_penddulum_nb4_nf2.csv')\n",
    "ARX_val_pendulum_pred=pd.read_csv('Results/ARX/Training and Validation/y_pred_val_df_ARX_penddulum_nb4_nf2.csv')\n",
    "\n",
    "# XGBoost\n",
    "XGB_train_true=pd.read_csv('Results/XGB/Training and Validation/y_true_train_df_XGB_nb0_nf10.csv')\n",
    "XGB_train_pred=pd.read_csv('Results/XGB/Training and Validation/y_pred_train_df_XGB_nb0_nf10.csv')\n",
    "\n",
    "XGB_val_true=pd.read_csv('Results/XGB/Training and Validation/y_true_val_df_XGB_nb0_nf10.csv')\n",
    "XGB_val_pred=pd.read_csv('Results/XGB/Training and Validation/y_pred_val_df_XGB_nb0_nf10.csv')\n",
    "\n",
    "#LSTM\n",
    "LSTM_train_true=pd.read_csv('Results/LSTM/Training and Validation/LSTM_train_true.csv')\n",
    "LSTM_train_pred=pd.read_csv('Results/LSTM/Training and Validation/LSTM_train_pred.csv')\n",
    "\n",
    "LSTM_val_true=pd.read_csv('Results/LSTM/Training and Validation/LSTM_val_true.csv')\n",
    "LSTM_val_pred=pd.read_csv('Results/LSTM/Training and Validation/LSTM_val_pred.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aeb4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust Training Data Size and index so all are same\n",
    "\n",
    "# ARX heave\n",
    "ARX_train_heave_true_adjusted = ARX_train_heave_true[:-5].reset_index(drop=True)\n",
    "ARX_train_heave_pred_adjusted = ARX_train_heave_pred[:-5].reset_index(drop=True)\n",
    "\n",
    "# ARX pitch\n",
    "ARX_train_pitch_true_adjusted = ARX_train_pitch_true[:-5].reset_index(drop=True)\n",
    "ARX_train_pitch_pred_adjusted = ARX_train_pitch_pred[:-5].reset_index(drop=True)\n",
    "\n",
    "# ARX pendulum\n",
    "ARX_train_pendulum_true_adjusted = ARX_train_pendulum_true[:-10].reset_index(drop=True)\n",
    "ARX_train_pendulum_pred_adjusted = ARX_train_pendulum_pred[:-10].reset_index(drop=True)\n",
    "\n",
    "# XGB\n",
    "XGB_train_true_adjusted = XGB_train_true[:-2].reset_index(drop=True)\n",
    "XGB_train_pred_adjusted = XGB_train_pred[:-2].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a3d282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARX heave\n",
    "ARX_val_heave_true_adjusted = ARX_val_heave_true[5:-59].reset_index(drop=True)\n",
    "ARX_val_heave_pred_adjusted = ARX_val_heave_pred[5:-59].reset_index(drop=True)\n",
    "\n",
    "# ARX pitch\n",
    "ARX_val_pitch_true_adjusted = ARX_val_pitch_true[5:-59].reset_index(drop=True)\n",
    "ARX_val_pitch_pred_adjusted = ARX_val_pitch_pred[5:-59].reset_index(drop=True)\n",
    "\n",
    "# ARX pendulum\n",
    "ARX_val_pendulum_true_adjusted = ARX_val_pendulum_true[5:-64].reset_index(drop=True)\n",
    "ARX_val_pendulum_pred_adjusted = ARX_val_pendulum_pred[5:-64].reset_index(drop=True)\n",
    "\n",
    "# XGB\n",
    "XGB_val_true_adjusted = XGB_val_true[5:-56].reset_index(drop=True)\n",
    "XGB_val_pred_adjusted = XGB_val_pred[5:-56].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abab93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lengths of adjusted training DataFrames:\")\n",
    "print(\"ARX Heave True:\", len(ARX_train_heave_true_adjusted))\n",
    "print(\"ARX Heave Pred:\", len(ARX_train_heave_pred_adjusted))\n",
    "print(\"ARX Pitch True:\", len(ARX_train_pitch_true_adjusted))\n",
    "print(\"ARX Pitch Pred:\", len(ARX_train_pitch_pred_adjusted))\n",
    "print(\"ARX Pendulum True:\", len(ARX_train_pendulum_true_adjusted))\n",
    "print(\"ARX Pendulum Pred:\", len(ARX_train_pendulum_pred_adjusted))\n",
    "print(\"XGB True:\", len(XGB_train_true_adjusted))\n",
    "print(\"XGB Pred:\", len(XGB_train_pred_adjusted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea73eb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that all True data sets are identical\n",
    "\n",
    "a = ARX_val_heave_true_adjusted['heave'].to_numpy()\n",
    "b = LSTM_val_true['heave'].to_numpy()\n",
    "c = XGB_val_true_adjusted['heave'].to_numpy()  # this is just 'a' again\n",
    "\n",
    "are_all_equal = np.all((a == b) & (b == c))  # or (a == b) & (a == c)\n",
    "\n",
    "print(\"All equal:\", are_all_equal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee32db4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_truth=XGB_train_true_adjusted\n",
    "Val_truth=XGB_val_true_adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06638346",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fc04f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ARX adjusted predictions\n",
    "arx_preds = {\n",
    "    'heave': ARX_train_heave_pred_adjusted['heave'],\n",
    "    'pitch': ARX_train_pitch_pred_adjusted['pitch'],\n",
    "    'pendulum': ARX_train_pendulum_pred_adjusted['pendulum'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b7ffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Define DoFs\n",
    "dofs = ['heave', 'pitch', 'pendulum']\n",
    "\n",
    "# Initialize metrics dictionary\n",
    "metrics = {}\n",
    "\n",
    "for dof in dofs:\n",
    "    y_true = Train_truth[dof]\n",
    "\n",
    "    metrics[dof] = {\n",
    "        # ARX\n",
    "        'ARX_R2': r2_score(y_true, arx_preds[dof]),\n",
    "        'ARX_RMSE': np.sqrt(mean_squared_error(y_true, arx_preds[dof])),\n",
    "\n",
    "        # XGBoost\n",
    "        'XGB_R2': r2_score(y_true, XGB_train_pred_adjusted[dof]),\n",
    "        'XGB_RMSE': np.sqrt(mean_squared_error(y_true, XGB_train_pred_adjusted[dof])),\n",
    "\n",
    "        # LSTM\n",
    "        'LSTM_R2': r2_score(y_true, LSTM_train_pred[f'{dof}_pred']),\n",
    "        'LSTM_RMSE': np.sqrt(mean_squared_error(y_true, LSTM_train_pred[f'{dof}_pred'])),\n",
    "    }\n",
    "\n",
    "# Convert to DataFrame for display\n",
    "metrics_df = pd.DataFrame(metrics).T\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fe2051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performnce aftr removing 1st 450 time steps \n",
    "# Define DoFs\n",
    "dofs = ['heave', 'pitch', 'pendulum']\n",
    "\n",
    "# Initialize metrics dictionary\n",
    "metrics = {}\n",
    "\n",
    "for dof in dofs:\n",
    "    y_true = Train_truth[dof][450:]\n",
    "\n",
    "    metrics[dof] = {\n",
    "        # ARX\n",
    "        'ARX_R2': r2_score(y_true, arx_preds[dof][450:]),\n",
    "        #'ARX_RMSE': np.sqrt(mean_squared_error(y_true, arx_preds[dof][450:])),\n",
    "\n",
    "        # XGBoost\n",
    "        'XGB_R2': r2_score(y_true, XGB_train_pred_adjusted[dof][450:]),\n",
    "        #'XGB_RMSE': np.sqrt(mean_squared_error(y_true, XGB_train_pred_adjusted[dof][450:])),\n",
    "\n",
    "        # LSTM\n",
    "        'LSTM_R2': r2_score(y_true, LSTM_train_pred[f'{dof}_pred'][450:]),\n",
    "        #'LSTM_RMSE': np.sqrt(mean_squared_error(y_true, LSTM_train_pred[f'{dof}_pred'][450:])),\n",
    "    }\n",
    "\n",
    "# Convert to DataFrame for display\n",
    "metrics_df = pd.DataFrame(metrics).T\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae559135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DoFs and corresponding y-axis units\n",
    "dofs = ['heave', 'pitch', 'pendulum']\n",
    "y_units = {\n",
    "    'heave': 'm',\n",
    "    'pitch': '°',\n",
    "    'pendulum': '°'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Loop through each DoF\n",
    "for dof in dofs:\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Ground Truth (solid black)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=Train_truth[dof],\n",
    "        mode='lines',\n",
    "        name=f'{dof.capitalize()} - Ground Truth',\n",
    "        line=dict(color='black', dash='solid')\n",
    "    ))\n",
    "\n",
    "    # ARX Prediction (dashed blue)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=arx_preds[dof],\n",
    "        mode='lines',\n",
    "        name='ARX Prediction',\n",
    "        line=dict(color='blue', dash='dash')\n",
    "    ))\n",
    "\n",
    "    # XGBoost Prediction (dashed red)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=XGB_train_pred_adjusted[dof],\n",
    "        mode='lines',\n",
    "        name='XGBoost-NARX Prediction',\n",
    "        line=dict(color='red', dash='dash')\n",
    "    ))\n",
    "\n",
    "    # LSTM Prediction (dashed green)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=LSTM_train_pred[f'{dof}_pred'],\n",
    "        mode='lines',\n",
    "        name='LSTM Prediction',\n",
    "        line=dict(color='green', dash='dash')\n",
    "    ))\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        title=f'Training Data Predictions - {dof.capitalize()}',\n",
    "        xaxis_title='Time Step',\n",
    "        yaxis_title=f'{dof.capitalize()} [{y_units[dof]}]',\n",
    "        template='plotly_white',\n",
    "        xaxis_range=[0, 6719]\n",
    "        \n",
    "    )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe059795",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define DoFs and corresponding y-axis units\n",
    "dofs = ['heave', 'pitch', 'pendulum']\n",
    "y_units = {\n",
    "    'heave': 'm',\n",
    "    'pitch': '°',\n",
    "    'pendulum': '°'\n",
    "}\n",
    "\n",
    "\n",
    "# Loop through each DoF\n",
    "for dof in dofs:\n",
    "    truth = Train_truth[dof]\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # ARX Absolute Error (blue)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=np.abs(truth - arx_preds[dof]),\n",
    "        mode='lines',\n",
    "        name='ARX Absolute Error',\n",
    "        line=dict(color='blue', dash='solid')\n",
    "    ))\n",
    "\n",
    "    # XGBoost Absolute Error (red)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=np.abs(truth - XGB_train_pred_adjusted[dof]),\n",
    "        mode='lines',\n",
    "        name='XGBoost Absolute Error',\n",
    "        line=dict(color='red', dash='solid')\n",
    "    ))\n",
    "\n",
    "    # LSTM Absolute Error (green)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=np.abs(truth - LSTM_train_pred[f'{dof}_pred']),\n",
    "        mode='lines',\n",
    "        name='LSTM Absolute Error',\n",
    "        line=dict(color='green', dash='solid')\n",
    "    ))\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        title=f'Training Data Absolute Prediction Error - {dof.capitalize()}',\n",
    "        xaxis_title='Time Step',\n",
    "        yaxis_title=f'Absolute Error [{y_units[dof]}]',\n",
    "        template='plotly_white'\n",
    "    )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb08b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Define DoFs and their units\n",
    "dofs = ['heave', 'pitch', 'pendulum']\n",
    "y_units = {'heave': 'm', 'pitch': '°', 'pendulum': '°'}\n",
    "\n",
    "y_ranges = {\n",
    "    'heave': [0, 1],\n",
    "    'pitch': [0, 0.3],\n",
    "    'pendulum': [0, 0.4]  # or whatever range you want\n",
    "}\n",
    "\n",
    "# Create box plots for each DoF\n",
    "for dof in dofs:\n",
    "    truth = Train_truth[dof]\n",
    "\n",
    "    # Calculate absolute errors\n",
    "    arx_error = np.abs(truth - arx_preds[dof])\n",
    "    xgb_error = np.abs(truth - XGB_train_pred_adjusted[dof])\n",
    "    lstm_error = np.abs(truth - LSTM_train_pred[f'{dof}_pred'])\n",
    "\n",
    "    # Create box plot\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Box(\n",
    "        y=arx_error,\n",
    "        name='ARX',\n",
    "        marker_color='blue',\n",
    "        boxmean='sd'\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Box(\n",
    "        y=xgb_error,\n",
    "        name='XGBoost-NARX',\n",
    "        marker_color='red',\n",
    "        boxmean='sd'\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Box(\n",
    "        y=lstm_error,\n",
    "        name='LSTM',\n",
    "        marker_color='green',\n",
    "        boxmean='sd'\n",
    "    ))\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f'Training Data Absolute Prediction Error - {dof.capitalize()}',\n",
    "        yaxis_title=f'Absolute Error [{y_units[dof]}]',\n",
    "        template='plotly_white',\n",
    "        width=600,     # Width in pixels\n",
    "        height=400,\n",
    "        yaxis=dict(range=y_ranges[dof]),\n",
    "        \n",
    "    )\n",
    "    fig.update_layout(showlegend=False)\n",
    "\n",
    "    # Save to file\n",
    "    fig.write_image(f\"Results/training plots/{dof}_box.png\")\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3130b6",
   "metadata": {},
   "source": [
    "## Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b109707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ARX adjusted predictions\n",
    "arx_preds_val = {\n",
    "    'heave': ARX_val_heave_pred_adjusted['heave'],\n",
    "    'pitch': ARX_val_pitch_pred_adjusted['pitch'],\n",
    "    'pendulum': ARX_val_pendulum_pred_adjusted['pendulum'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34253f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DoFs\n",
    "dofs = ['heave', 'pitch', 'pendulum']\n",
    "\n",
    "# Initialize metrics dictionary\n",
    "metrics = {}\n",
    "\n",
    "for dof in dofs:\n",
    "    y_true_val = Val_truth[dof]\n",
    "\n",
    "    metrics[dof] = {\n",
    "        # ARX\n",
    "        'ARX_R2': r2_score(y_true_val, arx_preds_val[dof]),\n",
    "        'ARX_RMSE': np.sqrt(mean_squared_error(y_true_val, arx_preds_val[dof])),\n",
    "\n",
    "        # XGBoost\n",
    "        'XGB_R2': r2_score(y_true_val, XGB_val_pred_adjusted[dof]),\n",
    "        'XGB_RMSE': np.sqrt(mean_squared_error(y_true_val, XGB_val_pred_adjusted[dof])),\n",
    "\n",
    "        # LSTM\n",
    "        'LSTM_R2': r2_score(y_true_val, LSTM_val_pred[f'{dof}_pred']),\n",
    "        'LSTM_RMSE': np.sqrt(mean_squared_error(y_true_val, LSTM_val_pred[f'{dof}_pred'])),\n",
    "    }\n",
    "\n",
    "# Convert to DataFrame for display\n",
    "metrics_df = pd.DataFrame(metrics).T\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e10e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVING 1ST 450 POINTS\n",
    "# Define DoFs\n",
    "dofs = ['heave', 'pitch', 'pendulum']\n",
    "\n",
    "# Initialize metrics dictionary\n",
    "metrics = {}\n",
    "\n",
    "for dof in dofs:\n",
    "    y_true_val = Val_truth[dof][450:]\n",
    "\n",
    "    metrics[dof] = {\n",
    "        # ARX\n",
    "        'ARX_R2': r2_score(y_true_val, arx_preds_val[dof][450:]),\n",
    "        #'ARX_RMSE': np.sqrt(mean_squared_error(y_true_val, arx_preds_val[dof][450:])),\n",
    "\n",
    "        # XGBoost\n",
    "        'XGB_R2': r2_score(y_true_val, XGB_val_pred_adjusted[dof][450:]),\n",
    "        #'XGB_RMSE': np.sqrt(mean_squared_error(y_true_val, XGB_val_pred_adjusted[dof][450:])),\n",
    "\n",
    "        # LSTM\n",
    "        'LSTM_R2': r2_score(y_true_val, LSTM_val_pred[f'{dof}_pred'][450:]),\n",
    "        #'LSTM_RMSE': np.sqrt(mean_squared_error(y_true_val, LSTM_val_pred[f'{dof}_pred'][450:])),\n",
    "    }\n",
    "\n",
    "# Convert to DataFrame for display\n",
    "metrics_df = pd.DataFrame(metrics).T\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c660ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DoFs and corresponding y-axis units\n",
    "dofs = ['heave', 'pitch', 'pendulum']\n",
    "y_units = {\n",
    "    'heave': 'm',\n",
    "    'pitch': '°',\n",
    "    'pendulum': '°'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Loop through each DoF\n",
    "for dof in dofs:\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Ground Truth (solid black)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=Val_truth[dof],\n",
    "        mode='lines',\n",
    "        name=f'{dof.capitalize()} - Ground Truth',\n",
    "        line=dict(color='black', dash='solid')\n",
    "    ))\n",
    "\n",
    "    # ARX Prediction (dashed blue)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=arx_preds_val[dof],\n",
    "        mode='lines',\n",
    "        name='ARX Prediction',\n",
    "        line=dict(color='blue', dash='dash')\n",
    "    ))\n",
    "\n",
    "    # XGBoost Prediction (dashed red)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=XGB_val_pred_adjusted[dof],\n",
    "        mode='lines',\n",
    "        name='XGBoost-NARX Prediction',\n",
    "        line=dict(color='red', dash='dash')\n",
    "    ))\n",
    "\n",
    "    # LSTM Prediction (dashed green)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=LSTM_val_pred[f'{dof}_pred'],\n",
    "        mode='lines',\n",
    "        name='LSTM Prediction',\n",
    "        line=dict(color='green', dash='dash')\n",
    "    ))\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        title=f'Validation Data Predictions - {dof.capitalize()}',\n",
    "        xaxis_title='Time Step',\n",
    "        yaxis_title=f'{dof.capitalize()} [{y_units[dof]}]',\n",
    "        template='plotly_white',\n",
    "        xaxis_range=[0, 6719]\n",
    "    )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52debf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define DoFs and corresponding y-axis units\n",
    "dofs = ['heave', 'pitch', 'pendulum']\n",
    "y_units = {\n",
    "    'heave': 'm',\n",
    "    'pitch': '°',\n",
    "    'pendulum': '°'\n",
    "}\n",
    "\n",
    "\n",
    "# Loop through each DoF\n",
    "for dof in dofs:\n",
    "    truth = Val_truth[dof]\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # ARX Absolute Error (blue)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=np.abs(truth - arx_preds_val[dof]),\n",
    "        mode='lines',\n",
    "        name='ARX Absolute Error',\n",
    "        line=dict(color='blue', dash='solid')\n",
    "    ))\n",
    "\n",
    "    # XGBoost Absolute Error (red)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=np.abs(truth - XGB_val_pred_adjusted[dof]),\n",
    "        mode='lines',\n",
    "        name='XGBoost Absolute Error',\n",
    "        line=dict(color='red', dash='solid')\n",
    "    ))\n",
    "\n",
    "    # LSTM Absolute Error (green)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=np.abs(truth - LSTM_val_pred[f'{dof}_pred']),\n",
    "        mode='lines',\n",
    "        name='LSTM Absolute Error',\n",
    "        line=dict(color='green', dash='solid')\n",
    "    ))\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        title=f'Validation Data Absolute Prediction Error - {dof.capitalize()}',\n",
    "        xaxis_title='Time Step',\n",
    "        yaxis_title=f'Absolute Error [{y_units[dof]}]',\n",
    "        template='plotly_white'\n",
    "    )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DoFs and their units\n",
    "dofs = ['heave', 'pitch', 'pendulum']\n",
    "y_units = {'heave': 'm', 'pitch': '°', 'pendulum': '°'}\n",
    "\n",
    "\n",
    "\n",
    "# Create box plots for each DoF\n",
    "for dof in dofs:\n",
    "    truth = Val_truth[dof]\n",
    "\n",
    "    # Calculate absolute errors\n",
    "    arx_error = np.abs(truth - arx_preds_val[dof])\n",
    "    xgb_error = np.abs(truth - XGB_val_pred_adjusted[dof])\n",
    "    lstm_error = np.abs(truth - LSTM_val_pred[f'{dof}_pred'])\n",
    "\n",
    "    # Create box plot\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Box(\n",
    "        y=arx_error,\n",
    "        name='ARX',\n",
    "        marker_color='blue',\n",
    "        boxmean='sd'\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Box(\n",
    "        y=xgb_error,\n",
    "        name='XGBoost-NARX',\n",
    "        marker_color='red',\n",
    "        boxmean='sd'\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Box(\n",
    "        y=lstm_error,\n",
    "        name='LSTM',\n",
    "        marker_color='green',\n",
    "        boxmean='sd'\n",
    "    ))\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f'Validation Data Absolute Prediction Error - {dof.capitalize()}',\n",
    "        yaxis_title=f'Absolute Error [{y_units[dof]}]',\n",
    "        template='plotly_white',\n",
    "        width=600,     # Width in pixels\n",
    "        height=400,\n",
    "                yaxis=dict(range=y_ranges[dof]),\n",
    "\n",
    "        \n",
    "    )\n",
    "    fig.update_layout(showlegend=False)\n",
    "\n",
    "    fig.write_image(f\"Results/Validation plots/{dof}_box.png\")\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfec4ce",
   "metadata": {},
   "source": [
    "# Loading testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876661a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the folder path\n",
    "folder_path = 'Results/ARX/Testing/heave'\n",
    "\n",
    "# Create an empty dictionary to hold the DataFrames\n",
    "csv_data_ARX_heave = {}\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        # Use filename (without .csv) as key\n",
    "        key = os.path.splitext(filename)[0]\n",
    "        csv_data_ARX_heave[key] = pd.read_csv(file_path)\n",
    "\n",
    "# Example: Access one of the loaded DataFrames\n",
    "print(csv_data_ARX_heave.keys())  # Shows all loaded file names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98140964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the folder path\n",
    "folder_path = 'Results/ARX/Testing/pitch'\n",
    "\n",
    "# Create an empty dictionary to hold the DataFrames\n",
    "csv_data_ARX_pitch = {}\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        # Use filename (without .csv) as key\n",
    "        key = os.path.splitext(filename)[0]\n",
    "        csv_data_ARX_pitch[key] = pd.read_csv(file_path)\n",
    "\n",
    "# Example: Access one of the loaded DataFrames\n",
    "print(csv_data_ARX_pitch.keys())  # Shows all loaded file names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278363bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the folder path\n",
    "folder_path = 'Results/ARX/Testing/pendulum'\n",
    "\n",
    "# Create an empty dictionary to hold the DataFrames\n",
    "csv_data_ARX_pendulum = {}\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        # Use filename (without .csv) as key\n",
    "        key = os.path.splitext(filename)[0]\n",
    "        csv_data_ARX_pendulum[key] = pd.read_csv(file_path)\n",
    "\n",
    "# Example: Access one of the loaded DataFrames\n",
    "print(csv_data_ARX_pendulum.keys())  # Shows all loaded file names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de78f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the folder path\n",
    "folder_path = 'Results/XGB/Testing'\n",
    "\n",
    "# Create an empty dictionary to hold the DataFrames\n",
    "csv_data_XGB = {}\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        # Use filename (without .csv) as key\n",
    "        key = os.path.splitext(filename)[0]\n",
    "        csv_data_XGB[key] = pd.read_csv(file_path)\n",
    "\n",
    "# Example: Access one of the loaded DataFrames\n",
    "print(csv_data_XGB.keys())  # Shows all loaded file names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51878f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the folder path\n",
    "folder_path = 'Results/LSTM/Testing'\n",
    "\n",
    "# Create an empty dictionary to hold the DataFrames\n",
    "csv_data_LSTM = {}\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        # Use filename (without .csv) as key\n",
    "        key = os.path.splitext(filename)[0]\n",
    "        csv_data_LSTM[key] = pd.read_csv(file_path)\n",
    "\n",
    "# Example: Access one of the loaded DataFrames\n",
    "print(csv_data_LSTM.keys())  # Shows all loaded file names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29964399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T10p2s_Hs1m\n",
    "ARX_heave_T10p2s_Hs1m_true = csv_data_ARX_heave['y_true_test_heave_T10p2s_Hs1m'][5:].reset_index(drop=True)\n",
    "ARX_heave_T10p2s_Hs1m_pred = csv_data_ARX_heave['y_pred_test_heave_T10p2s_Hs1m'][5:].reset_index(drop=True)\n",
    "\n",
    "# T10p2s_Hs4m\n",
    "ARX_heave_T10p2s_Hs4m_true = csv_data_ARX_heave['y_true_test_heave_T10p2s_Hs4m'][5:].reset_index(drop=True)\n",
    "ARX_heave_T10p2s_Hs4m_pred = csv_data_ARX_heave['y_pred_test_heave_T10p2s_Hs4m'][5:].reset_index(drop=True)\n",
    "\n",
    "# T4p5s_Hs1m\n",
    "ARX_heave_T4p5s_Hs1m_true = csv_data_ARX_heave['y_true_test_heave_T4p5s_Hs1m'][5:].reset_index(drop=True)\n",
    "ARX_heave_T4p5s_Hs1m_pred = csv_data_ARX_heave['y_pred_test_heave_T4p5s_Hs1m'][5:].reset_index(drop=True)\n",
    "\n",
    "# T4p5s_Hs2m\n",
    "ARX_heave_T4p5s_Hs2m_true = csv_data_ARX_heave['y_true_test_heave_T4p5s_Hs2m'][5:].reset_index(drop=True)\n",
    "ARX_heave_T4p5s_Hs2m_pred = csv_data_ARX_heave['y_pred_test_heave_T4p5s_Hs2m'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp10p2_Hs2m\n",
    "ARX_heave_Tp10p2_Hs2m_true = csv_data_ARX_heave['y_true_test_heave_Tp10p2_Hs2m'][5:].reset_index(drop=True)\n",
    "ARX_heave_Tp10p2_Hs2m_pred = csv_data_ARX_heave['y_pred_test_heave_Tp10p2_Hs2m'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs1m\n",
    "ARX_heave_Tp6p8s_Hs1m_true = csv_data_ARX_heave['y_true_test_heave_Tp6p8s_Hs1m'][5:].reset_index(drop=True)\n",
    "ARX_heave_Tp6p8s_Hs1m_pred = csv_data_ARX_heave['y_pred_test_heave_Tp6p8s_Hs1m'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs2m\n",
    "ARX_heave_Tp6p8s_Hs2m_true = csv_data_ARX_heave['y_true_test_heave_Tp6p8s_Hs2m'][5:].reset_index(drop=True)\n",
    "ARX_heave_Tp6p8s_Hs2m_pred = csv_data_ARX_heave['y_pred_test_heave_Tp6p8s_Hs2m'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs4m\n",
    "ARX_heave_Tp6p8s_Hs4m_true = csv_data_ARX_heave['y_true_test_heave_Tp6p8s_Hs4m'][5:].reset_index(drop=True)\n",
    "ARX_heave_Tp6p8s_Hs4m_pred = csv_data_ARX_heave['y_pred_test_heave_Tp6p8s_Hs4m'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs6m\n",
    "ARX_heave_Tp6p8s_Hs6m_true = csv_data_ARX_heave['y_true_test_heave_Tp6p8s_Hs6m'][5:].reset_index(drop=True)\n",
    "ARX_heave_Tp6p8s_Hs6m_pred = csv_data_ARX_heave['y_pred_test_heave_Tp6p8s_Hs6m'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs8m\n",
    "ARX_heave_Tp6p8s_Hs8m_true = csv_data_ARX_heave['y_true_test_heave_Tp6p8s_Hs8m'][5:].reset_index(drop=True)\n",
    "ARX_heave_Tp6p8s_Hs8m_pred = csv_data_ARX_heave['y_pred_test_heave_Tp6p8s_Hs8m'][5:].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552d0456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T10p2s_Hs1m\n",
    "ARX_pitch_T10p2s_Hs1m_true = csv_data_ARX_pitch['y_true_test_pitch_T10p2s_Hs1m'][5:].reset_index(drop=True)\n",
    "ARX_pitch_T10p2s_Hs1m_pred = csv_data_ARX_pitch['y_pred_test_pitch_T10p2s_Hs1m'][5:].reset_index(drop=True)\n",
    "\n",
    "# T10p2s_Hs4m\n",
    "ARX_pitch_T10p2s_Hs4m_true = csv_data_ARX_pitch['y_true_test_pitch_T10p2s_Hs4m'][5:].reset_index(drop=True)\n",
    "ARX_pitch_T10p2s_Hs4m_pred = csv_data_ARX_pitch['y_pred_test_pitch_T10p2s_Hs4m'][5:].reset_index(drop=True)\n",
    "\n",
    "# T4p5s_Hs1m\n",
    "ARX_pitch_T4p5s_Hs1m_true = csv_data_ARX_pitch['y_true_test_pitch_T4p5s_Hs1m'][5:].reset_index(drop=True)\n",
    "ARX_pitch_T4p5s_Hs1m_pred = csv_data_ARX_pitch['y_pred_test_pitch_T4p5s_Hs1m'][5:].reset_index(drop=True)\n",
    "\n",
    "# T4p5s_Hs2m\n",
    "ARX_pitch_T4p5s_Hs2m_true = csv_data_ARX_pitch['y_true_test_pitch_T4p5s_Hs2m'][5:].reset_index(drop=True)\n",
    "ARX_pitch_T4p5s_Hs2m_pred = csv_data_ARX_pitch['y_pred_test_pitch_T4p5s_Hs2m'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp10p2_Hs2m\n",
    "ARX_pitch_Tp10p2_Hs2m_true = csv_data_ARX_pitch['y_true_test_pitch_Tp10p2_Hs2m'][5:].reset_index(drop=True)\n",
    "ARX_pitch_Tp10p2_Hs2m_pred = csv_data_ARX_pitch['y_pred_test_pitch_Tp10p2_Hs2m'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs1m\n",
    "ARX_pitch_Tp6p8s_Hs1m_true = csv_data_ARX_pitch['y_true_test_pitch_Tp6p8s_Hs1m'][5:].reset_index(drop=True)\n",
    "ARX_pitch_Tp6p8s_Hs1m_pred = csv_data_ARX_pitch['y_pred_test_pitch_Tp6p8s_Hs1m'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs2m\n",
    "ARX_pitch_Tp6p8s_Hs2m_true = csv_data_ARX_pitch['y_true_test_pitch_Tp6p8s_Hs2m'][5:].reset_index(drop=True)\n",
    "ARX_pitch_Tp6p8s_Hs2m_pred = csv_data_ARX_pitch['y_pred_test_pitch_Tp6p8s_Hs2m'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs4m\n",
    "ARX_pitch_Tp6p8s_Hs4m_true = csv_data_ARX_pitch['y_true_test_pitch_Tp6p8s_Hs4m'][5:].reset_index(drop=True)\n",
    "ARX_pitch_Tp6p8s_Hs4m_pred = csv_data_ARX_pitch['y_pred_test_pitch_Tp6p8s_Hs4m'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs6m\n",
    "ARX_pitch_Tp6p8s_Hs6m_true = csv_data_ARX_pitch['y_true_test_pitch_Tp6p8s_Hs6m'][5:].reset_index(drop=True)\n",
    "ARX_pitch_Tp6p8s_Hs6m_pred = csv_data_ARX_pitch['y_pred_test_pitch_Tp6p8s_Hs6m'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs8m\n",
    "ARX_pitch_Tp6p8s_Hs8m_true = csv_data_ARX_pitch['y_true_test_pitch_Tp6p8s_Hs8m'][5:].reset_index(drop=True)\n",
    "ARX_pitch_Tp6p8s_Hs8m_pred = csv_data_ARX_pitch['y_pred_test_pitch_Tp6p8s_Hs8m'][5:].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b18b8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T10p2s_Hs1m\n",
    "ARX_pendulum_T10p2s_Hs1m_true = csv_data_ARX_pendulum['y_true_test_pitch_T10p2s_Hs1m'][5:].reset_index(drop=True)\n",
    "ARX_pendulum_T10p2s_Hs1m_pred = csv_data_ARX_pendulum['y_pred_test_dfT10p2s_Hs1m'][5:].reset_index(drop=True)\n",
    "\n",
    "# T10p2s_Hs4m\n",
    "ARX_pendulum_T10p2s_Hs4m_true = csv_data_ARX_pendulum['y_true_test_pitch_T10p2s_Hs4m'][5:].reset_index(drop=True)\n",
    "ARX_pendulum_T10p2s_Hs4m_pred = csv_data_ARX_pendulum['y_pred_test_dfT10p2s_Hs4m'][5:].reset_index(drop=True)\n",
    "\n",
    "# T4p5s_Hs1m\n",
    "ARX_pendulum_T4p5s_Hs1m_true = csv_data_ARX_pendulum['y_true_test_pitch_T4p5s_Hs1m'][5:].reset_index(drop=True)\n",
    "ARX_pendulum_T4p5s_Hs1m_pred = csv_data_ARX_pendulum['y_pred_test_dfT4p5s_Hs1m'][5:].reset_index(drop=True)\n",
    "\n",
    "# T4p5s_Hs2m\n",
    "ARX_pendulum_T4p5s_Hs2m_true = csv_data_ARX_pendulum['y_true_test_pitch_T4p5s_Hs2m'][5:].reset_index(drop=True)\n",
    "ARX_pendulum_T4p5s_Hs2m_pred = csv_data_ARX_pendulum['y_pred_test_dfT4p5s_Hs2m'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp10p2_Hs2m\n",
    "ARX_pendulum_Tp10p2_Hs2m_true = csv_data_ARX_pendulum['y_true_test_pitch_Tp10p2_Hs2m'][5:].reset_index(drop=True)\n",
    "ARX_pendulum_Tp10p2_Hs2m_pred = csv_data_ARX_pendulum['y_pred_test_dfTp10p2_Hs2m'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs1m\n",
    "ARX_pendulum_Tp6p8s_Hs1m_true = csv_data_ARX_pendulum['y_true_test_pitch_Tp6p8s_Hs1m'][5:].reset_index(drop=True)\n",
    "ARX_pendulum_Tp6p8s_Hs1m_pred = csv_data_ARX_pendulum['y_pred_test_dfTp6p8s_Hs1m'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs2m\n",
    "ARX_pendulum_Tp6p8s_Hs2m_true = csv_data_ARX_pendulum['y_true_test_pitch_Tp6p8s_Hs2m'][5:].reset_index(drop=True)\n",
    "ARX_pendulum_Tp6p8s_Hs2m_pred = csv_data_ARX_pendulum['y_pred_test_dfTp6p8s_Hs2m'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs4m\n",
    "ARX_pendulum_Tp6p8s_Hs4m_true = csv_data_ARX_pendulum['y_true_test_pitch_Tp6p8s_Hs4m'][5:].reset_index(drop=True)\n",
    "ARX_pendulum_Tp6p8s_Hs4m_pred = csv_data_ARX_pendulum['y_pred_test_dfTp6p8s_Hs4m'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs6m\n",
    "ARX_pendulum_Tp6p8s_Hs6m_true = csv_data_ARX_pendulum['y_true_test_pitch_Tp6p8s_Hs6m'][5:].reset_index(drop=True)\n",
    "ARX_pendulum_Tp6p8s_Hs6m_pred = csv_data_ARX_pendulum['y_pred_test_dfTp6p8s_Hs6m'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs8m\n",
    "ARX_pendulum_Tp6p8s_Hs8m_true = csv_data_ARX_pendulum['y_true_test_pitch_Tp6p8s_Hs8m'][5:].reset_index(drop=True)\n",
    "ARX_pendulum_Tp6p8s_Hs8m_pred = csv_data_ARX_pendulum['y_pred_test_dfTp6p8s_Hs8m'][5:].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba99f484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T10p2s_Hs1m\n",
    "XGB_T10p2s_Hs1m_true = csv_data_XGB['Xgboost_3dof_ver2_extra_na2_nb0_nf10.joblib_case_T10p2s_Hs1m_y_true'][5:].reset_index(drop=True)\n",
    "XGB_T10p2s_Hs1m_pred = csv_data_XGB['Xgboost_3dof_ver2_extra_na2_nb0_nf10.joblib_case_T10p2s_Hs1m_y_pred'][5:].reset_index(drop=True)\n",
    "\n",
    "# T10p2s_Hs4m\n",
    "XGB_T10p2s_Hs4m_true = csv_data_XGB['Xgboost_3dof_ver2_extra_na2_nb0_nf10.joblib_case_T10p2s_Hs4m_y_true'][5:].reset_index(drop=True)\n",
    "XGB_T10p2s_Hs4m_pred = csv_data_XGB['Xgboost_3dof_ver2_extra_na2_nb0_nf10.joblib_case_T10p2s_Hs4m_y_pred'][5:].reset_index(drop=True)\n",
    "\n",
    "# T4p5s_Hs1m\n",
    "XGB_T4p5s_Hs1m_true = csv_data_XGB['Xgboost_3dof_ver2_extra_na2_nb0_nf10.joblib_case_T4p5s_Hs1m_y_true'][5:].reset_index(drop=True)\n",
    "XGB_T4p5s_Hs1m_pred = csv_data_XGB['Xgboost_3dof_ver2_extra_na2_nb0_nf10.joblib_case_T4p5s_Hs1m_y_pred'][5:].reset_index(drop=True)\n",
    "\n",
    "# T4p5s_Hs2m\n",
    "XGB_T4p5s_Hs2m_true = csv_data_XGB['Xgboost_3dof_ver2_extra_na2_nb0_nf10.joblib_case_T4p5s_Hs2m_y_true'][5:].reset_index(drop=True)\n",
    "XGB_T4p5s_Hs2m_pred = csv_data_XGB['Xgboost_3dof_ver2_extra_na2_nb0_nf10.joblib_case_T4p5s_Hs2m_y_pred'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp10p2_Hs2m\n",
    "XGB_Tp10p2_Hs2m_true = csv_data_XGB['Xgboost_3dof_ver2_extra_na2_nb0_nf10.joblib_case_Tp10p2_Hs2m_y_true'][5:].reset_index(drop=True)\n",
    "XGB_Tp10p2_Hs2m_pred = csv_data_XGB['Xgboost_3dof_ver2_extra_na2_nb0_nf10.joblib_case_Tp10p2_Hs2m_y_pred'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs1m\n",
    "XGB_Tp6p8s_Hs1m_true = csv_data_XGB['Xgboost_3dof_ver2_extra_na2_nb0_nf10.joblib_case_Tp6p8s_Hs1m_y_true'][5:].reset_index(drop=True)\n",
    "XGB_Tp6p8s_Hs1m_pred = csv_data_XGB['Xgboost_3dof_ver2_extra_na2_nb0_nf10.joblib_case_Tp6p8s_Hs1m_y_pred'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs2m\n",
    "XGB_Tp6p8s_Hs2m_true = csv_data_XGB['Xgboost_3dof_ver2_extra_na2_nb0_nf10.joblib_case_Tp6p8s_Hs2m_y_true'][5:].reset_index(drop=True)\n",
    "XGB_Tp6p8s_Hs2m_pred = csv_data_XGB['Xgboost_3dof_ver2_extra_na2_nb0_nf10.joblib_case_Tp6p8s_Hs2m_y_pred'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs4m\n",
    "XGB_Tp6p8s_Hs4m_true = csv_data_XGB['Xgboost_3dof_ver2_extra_na2_nb0_nf10.joblib_case_Tp6p8s_Hs4m_y_true'][5:].reset_index(drop=True)\n",
    "XGB_Tp6p8s_Hs4m_pred = csv_data_XGB['Xgboost_3dof_ver2_extra_na2_nb0_nf10.joblib_case_Tp6p8s_Hs4m_y_pred'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs6m\n",
    "XGB_Tp6p8s_Hs6m_true = csv_data_XGB['Xgboost_3dof_ver2_extra_na2_nb0_nf10.joblib_case_Tp6p8s_Hs6m_y_true'][5:].reset_index(drop=True)\n",
    "XGB_Tp6p8s_Hs6m_pred = csv_data_XGB['Xgboost_3dof_ver2_extra_na2_nb0_nf10.joblib_case_Tp6p8s_Hs6m_y_pred'][5:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs8m\n",
    "XGB_Tp6p8s_Hs8m_true = csv_data_XGB['Xgboost_3dof_ver2_extra_na2_nb0_nf10.joblib_case_Tp6p8s_Hs8m_y_true'][5:].reset_index(drop=True)\n",
    "XGB_Tp6p8s_Hs8m_pred = csv_data_XGB['Xgboost_3dof_ver2_extra_na2_nb0_nf10.joblib_case_Tp6p8s_Hs8m_y_pred'][5:].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700c94ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T10p2s_Hs1m\n",
    "LSTM_T10p2s_Hs1m_true = csv_data_LSTM['LSTM_true_T10p2s_Hs1m'][:].reset_index(drop=True)\n",
    "LSTM_T10p2s_Hs1m_pred = csv_data_LSTM['LSTM_pred_T10p2s_Hs1m'][:].reset_index(drop=True)\n",
    "\n",
    "# T10p2s_Hs4m\n",
    "LSTM_T10p2s_Hs4m_true = csv_data_LSTM['LSTM_true_T10p2s_Hs4m'][:].reset_index(drop=True)\n",
    "LSTM_T10p2s_Hs4m_pred = csv_data_LSTM['LSTM_pred_T10p2s_Hs4m'][:].reset_index(drop=True)\n",
    "\n",
    "# T4p5s_Hs1m\n",
    "LSTM_T4p5s_Hs1m_true = csv_data_LSTM['LSTM_true_T4p5s_Hs1m'][:].reset_index(drop=True)\n",
    "LSTM_T4p5s_Hs1m_pred = csv_data_LSTM['LSTM_pred_T4p5s_Hs1m'][:].reset_index(drop=True)\n",
    "\n",
    "# T4p5s_Hs2m\n",
    "LSTM_T4p5s_Hs2m_true = csv_data_LSTM['LSTM_true_T4p5s_Hs2m'][:].reset_index(drop=True)\n",
    "LSTM_T4p5s_Hs2m_pred = csv_data_LSTM['LSTM_pred_T4p5s_Hs2m'][:].reset_index(drop=True)\n",
    "\n",
    "# Tp10p2_Hs2m\n",
    "LSTM_Tp10p2_Hs2m_true = csv_data_LSTM['LSTM_true_Tp10p2_Hs2m'][:].reset_index(drop=True)\n",
    "LSTM_Tp10p2_Hs2m_pred = csv_data_LSTM['LSTM_pred_Tp10p2_Hs2m'][:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs1m\n",
    "LSTM_Tp6p8s_Hs1m_true = csv_data_LSTM['LSTM_true_Tp6p8s_Hs1m'][:].reset_index(drop=True)\n",
    "LSTM_Tp6p8s_Hs1m_pred = csv_data_LSTM['LSTM_pred_Tp6p8s_Hs1m'][:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs2m\n",
    "LSTM_Tp6p8s_Hs2m_true = csv_data_LSTM['LSTM_true_Tp6p8s_Hs2m'][:].reset_index(drop=True)\n",
    "LSTM_Tp6p8s_Hs2m_pred = csv_data_LSTM['LSTM_pred_Tp6p8s_Hs2m'][:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs4m\n",
    "LSTM_Tp6p8s_Hs4m_true = csv_data_LSTM['LSTM_true_Tp6p8s_Hs4m'][:].reset_index(drop=True)\n",
    "LSTM_Tp6p8s_Hs4m_pred = csv_data_LSTM['LSTM_pred_Tp6p8s_Hs4m'][:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs6m\n",
    "LSTM_Tp6p8s_Hs6m_true = csv_data_LSTM['LSTM_true_Tp6p8s_Hs6m'][:].reset_index(drop=True)\n",
    "LSTM_Tp6p8s_Hs6m_pred = csv_data_LSTM['LSTM_pred_Tp6p8s_Hs6m'][:].reset_index(drop=True)\n",
    "\n",
    "# Tp6p8s_Hs8m\n",
    "LSTM_Tp6p8s_Hs8m_true = csv_data_LSTM['LSTM_true_Tp6p8s_Hs8m'][:].reset_index(drop=True)\n",
    "LSTM_Tp6p8s_Hs8m_pred = csv_data_LSTM['LSTM_pred_Tp6p8s_Hs8m'][:].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ca6afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra samples at the end to match batch size\n",
    "def adjust_for_batch(X):\n",
    "    n = (X.shape[0] // 64) * 64\n",
    "    return X[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed77ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of variable names as strings\n",
    "data_names = [\n",
    "    \"ARX_heave_T10p2s_Hs1m_true\", \"ARX_heave_T10p2s_Hs1m_pred\",\n",
    "    \"ARX_heave_T10p2s_Hs4m_true\", \"ARX_heave_T10p2s_Hs4m_pred\",\n",
    "    \"ARX_heave_T4p5s_Hs1m_true\", \"ARX_heave_T4p5s_Hs1m_pred\",\n",
    "    \"ARX_heave_T4p5s_Hs2m_true\", \"ARX_heave_T4p5s_Hs2m_pred\",\n",
    "    \"ARX_heave_Tp10p2_Hs2m_true\", \"ARX_heave_Tp10p2_Hs2m_pred\",\n",
    "    \"ARX_heave_Tp6p8s_Hs1m_true\", \"ARX_heave_Tp6p8s_Hs1m_pred\",\n",
    "    \"ARX_heave_Tp6p8s_Hs2m_true\", \"ARX_heave_Tp6p8s_Hs2m_pred\",\n",
    "    \"ARX_heave_Tp6p8s_Hs4m_true\", \"ARX_heave_Tp6p8s_Hs4m_pred\",\n",
    "    \"ARX_heave_Tp6p8s_Hs6m_true\", \"ARX_heave_Tp6p8s_Hs6m_pred\",\n",
    "    \"ARX_heave_Tp6p8s_Hs8m_true\", \"ARX_heave_Tp6p8s_Hs8m_pred\",\n",
    "    \"ARX_pitch_T10p2s_Hs1m_true\", \"ARX_pitch_T10p2s_Hs1m_pred\",\n",
    "    \"ARX_pitch_T10p2s_Hs4m_true\", \"ARX_pitch_T10p2s_Hs4m_pred\",\n",
    "    \"ARX_pitch_T4p5s_Hs1m_true\", \"ARX_pitch_T4p5s_Hs1m_pred\",\n",
    "    \"ARX_pitch_T4p5s_Hs2m_true\", \"ARX_pitch_T4p5s_Hs2m_pred\",\n",
    "    \"ARX_pitch_Tp10p2_Hs2m_true\", \"ARX_pitch_Tp10p2_Hs2m_pred\",\n",
    "    \"ARX_pitch_Tp6p8s_Hs1m_true\", \"ARX_pitch_Tp6p8s_Hs1m_pred\",\n",
    "    \"ARX_pitch_Tp6p8s_Hs2m_true\", \"ARX_pitch_Tp6p8s_Hs2m_pred\",\n",
    "    \"ARX_pitch_Tp6p8s_Hs4m_true\", \"ARX_pitch_Tp6p8s_Hs4m_pred\",\n",
    "    \"ARX_pitch_Tp6p8s_Hs6m_true\", \"ARX_pitch_Tp6p8s_Hs6m_pred\",\n",
    "    \"ARX_pitch_Tp6p8s_Hs8m_true\", \"ARX_pitch_Tp6p8s_Hs8m_pred\",\n",
    "    \"ARX_pendulum_T10p2s_Hs1m_true\", \"ARX_pendulum_T10p2s_Hs1m_pred\",\n",
    "    \"ARX_pendulum_T10p2s_Hs4m_true\", \"ARX_pendulum_T10p2s_Hs4m_pred\",\n",
    "    \"ARX_pendulum_T4p5s_Hs1m_true\", \"ARX_pendulum_T4p5s_Hs1m_pred\",\n",
    "    \"ARX_pendulum_T4p5s_Hs2m_true\", \"ARX_pendulum_T4p5s_Hs2m_pred\",\n",
    "    \"ARX_pendulum_Tp10p2_Hs2m_true\", \"ARX_pendulum_Tp10p2_Hs2m_pred\",\n",
    "    \"ARX_pendulum_Tp6p8s_Hs1m_true\", \"ARX_pendulum_Tp6p8s_Hs1m_pred\",\n",
    "    \"ARX_pendulum_Tp6p8s_Hs2m_true\", \"ARX_pendulum_Tp6p8s_Hs2m_pred\",\n",
    "    \"ARX_pendulum_Tp6p8s_Hs4m_true\", \"ARX_pendulum_Tp6p8s_Hs4m_pred\",\n",
    "    \"ARX_pendulum_Tp6p8s_Hs6m_true\", \"ARX_pendulum_Tp6p8s_Hs6m_pred\",\n",
    "    \"ARX_pendulum_Tp6p8s_Hs8m_true\", \"ARX_pendulum_Tp6p8s_Hs8m_pred\",\n",
    "    \"XGB_T10p2s_Hs1m_true\", \"XGB_T10p2s_Hs1m_pred\",\n",
    "    \"XGB_T10p2s_Hs4m_true\", \"XGB_T10p2s_Hs4m_pred\",\n",
    "    \"XGB_T4p5s_Hs1m_true\", \"XGB_T4p5s_Hs1m_pred\",\n",
    "    \"XGB_T4p5s_Hs2m_true\", \"XGB_T4p5s_Hs2m_pred\",\n",
    "    \"XGB_Tp10p2_Hs2m_true\", \"XGB_Tp10p2_Hs2m_pred\",\n",
    "    \"XGB_Tp6p8s_Hs1m_true\", \"XGB_Tp6p8s_Hs1m_pred\",\n",
    "    \"XGB_Tp6p8s_Hs2m_true\", \"XGB_Tp6p8s_Hs2m_pred\",\n",
    "    \"XGB_Tp6p8s_Hs4m_true\", \"XGB_Tp6p8s_Hs4m_pred\",\n",
    "    \"XGB_Tp6p8s_Hs6m_true\", \"XGB_Tp6p8s_Hs6m_pred\",\n",
    "    \"XGB_Tp6p8s_Hs8m_true\", \"XGB_Tp6p8s_Hs8m_pred\"\n",
    "]\n",
    "\n",
    "# Apply the function and store as new variables with \"_adjusted\" suffix\n",
    "for name in data_names:\n",
    "    original = globals()[name]\n",
    "    adjusted = adjust_for_batch(original)\n",
    "    globals()[name + \"_adjusted\"] = adjusted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ab3550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking\n",
    "# List of test cases to check\n",
    "test_cases = [\n",
    "    \"T10p2s_Hs1m\",\n",
    "    \"T10p2s_Hs4m\",\n",
    "    \"T4p5s_Hs1m\",\n",
    "    \"T4p5s_Hs2m\",\n",
    "    \"Tp10p2_Hs2m\",\n",
    "    \"Tp6p8s_Hs1m\",\n",
    "    \"Tp6p8s_Hs2m\",\n",
    "    \"Tp6p8s_Hs4m\",\n",
    "    \"Tp6p8s_Hs6m\",\n",
    "    \"Tp6p8s_Hs8m\"\n",
    "]\n",
    "\n",
    "for test in test_cases:\n",
    "    try:\n",
    "        a = globals()[f\"ARX_heave_{test}_true_adjusted\"]['heave'].to_numpy()\n",
    "        b = globals()[f\"LSTM_{test}_true\"]['heave'].to_numpy()\n",
    "        c = globals()[f\"XGB_{test}_true_adjusted\"]['heave'].to_numpy()\n",
    "\n",
    "        are_all_equal = np.all((a == b) & (b == c))\n",
    "        print(f\"{test}: All equal? {are_all_equal}\")\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"{test}: Missing variable {e}\")\n",
    "    except Exception as ex:\n",
    "        print(f\"{test}: Error - {ex}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971de71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking\n",
    "# List of test cases to check\n",
    "test_cases = [\n",
    "    \"T10p2s_Hs1m\",\n",
    "    \"T10p2s_Hs4m\",\n",
    "    \"T4p5s_Hs1m\",\n",
    "    \"T4p5s_Hs2m\",\n",
    "    \"Tp10p2_Hs2m\",\n",
    "    \"Tp6p8s_Hs1m\",\n",
    "    \"Tp6p8s_Hs2m\",\n",
    "    \"Tp6p8s_Hs4m\",\n",
    "    \"Tp6p8s_Hs6m\",\n",
    "    \"Tp6p8s_Hs8m\"\n",
    "]\n",
    "\n",
    "for test in test_cases:\n",
    "    try:\n",
    "        a = globals()[f\"ARX_pitch_{test}_true_adjusted\"]['pitch'].to_numpy()\n",
    "        b = globals()[f\"LSTM_{test}_true\"]['pitch'].to_numpy()\n",
    "        c = globals()[f\"XGB_{test}_true_adjusted\"]['pitch'].to_numpy()\n",
    "\n",
    "        are_all_equal = np.all((a == b) & (b == c))\n",
    "        print(f\"{test}: All equal? {are_all_equal}\")\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"{test}: Missing variable {e}\")\n",
    "    except Exception as ex:\n",
    "        print(f\"{test}: Error - {ex}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2dd39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking\n",
    "# List of test cases to check\n",
    "test_cases = [\n",
    "    \"T10p2s_Hs1m\",\n",
    "    \"T10p2s_Hs4m\",\n",
    "    \"T4p5s_Hs1m\",\n",
    "    \"T4p5s_Hs2m\",\n",
    "    \"Tp10p2_Hs2m\",\n",
    "    \"Tp6p8s_Hs1m\",\n",
    "    \"Tp6p8s_Hs2m\",\n",
    "    \"Tp6p8s_Hs4m\",\n",
    "    \"Tp6p8s_Hs6m\",\n",
    "    \"Tp6p8s_Hs8m\"\n",
    "]\n",
    "\n",
    "for test in test_cases:\n",
    "    try:\n",
    "        a = globals()[f\"ARX_pendulum_{test}_true_adjusted\"]['pendulum'].to_numpy()\n",
    "        b = globals()[f\"LSTM_{test}_true\"]['pendulum'].to_numpy()\n",
    "        c = globals()[f\"XGB_{test}_true_adjusted\"]['pendulum'].to_numpy()\n",
    "\n",
    "        are_all_equal = np.all((a == b) & (b == c))\n",
    "        print(f\"{test}: All equal? {are_all_equal}\")\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"{test}: Missing variable {e}\")\n",
    "    except Exception as ex:\n",
    "        print(f\"{test}: Error - {ex}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa55ea1e",
   "metadata": {},
   "source": [
    "## Testing Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c168a84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ARX adjusted predictions\n",
    "arx_preds_test = {\n",
    "    'heave': ARX_heave_Tp6p8s_Hs2m_pred_adjusted['heave'],\n",
    "    'pitch': ARX_pitch_Tp6p8s_Hs2m_pred_adjusted['pitch'],\n",
    "    'pendulum': ARX_pendulum_Tp6p8s_Hs2m_pred_adjusted['pendulum'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d42d46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DoFs\n",
    "dofs = ['heave', 'pitch', 'pendulum']\n",
    "\n",
    "# Initialize metrics dictionary\n",
    "metrics = {}\n",
    "\n",
    "for dof in dofs:\n",
    "    y_true_val = LSTM_Tp6p8s_Hs2m_true[dof]\n",
    "\n",
    "    metrics[dof] = {\n",
    "        # ARX\n",
    "        'ARX_R2': r2_score(y_true_val, arx_preds_test[dof]),\n",
    "        'ARX_RMSE': np.sqrt(mean_squared_error(y_true_val, arx_preds_test[dof])),\n",
    "\n",
    "        # XGBoost\n",
    "        'XGB_R2': r2_score(y_true_val, XGB_Tp6p8s_Hs2m_pred_adjusted[dof]),\n",
    "        'XGB_RMSE': np.sqrt(mean_squared_error(y_true_val, XGB_Tp6p8s_Hs2m_pred_adjusted[dof])),\n",
    "\n",
    "        # LSTM\n",
    "        'LSTM_R2': r2_score(y_true_val, LSTM_Tp6p8s_Hs2m_pred[f'{dof}_pred']),\n",
    "        'LSTM_RMSE': np.sqrt(mean_squared_error(y_true_val, LSTM_Tp6p8s_Hs2m_pred[f'{dof}_pred'])),\n",
    "    }\n",
    "\n",
    "# Convert to DataFrame for display\n",
    "metrics_df = pd.DataFrame(metrics).T\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc45cf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing 1st 450 time steps\n",
    "# Define DoFs\n",
    "dofs = ['heave', 'pitch', 'pendulum']\n",
    "\n",
    "# Initialize metrics dictionary\n",
    "metrics = {}\n",
    "\n",
    "for dof in dofs:\n",
    "    y_true_val = LSTM_Tp6p8s_Hs2m_true[dof][450:]\n",
    "\n",
    "    metrics[dof] = {\n",
    "        # ARX\n",
    "        'ARX_R2': r2_score(y_true_val, arx_preds_test[dof][450:]),\n",
    "       # 'ARX_RMSE': np.sqrt(mean_squared_error(y_true_val, arx_preds_test[dof][450:])),\n",
    "\n",
    "        # XGBoost\n",
    "        'XGB_R2': r2_score(y_true_val, XGB_Tp6p8s_Hs2m_pred_adjusted[dof][450:]),\n",
    "        #'XGB_RMSE': np.sqrt(mean_squared_error(y_true_val, XGB_Tp6p8s_Hs2m_pred_adjusted[dof][450:])),\n",
    "\n",
    "        # LSTM\n",
    "        'LSTM_R2': r2_score(y_true_val, LSTM_Tp6p8s_Hs2m_pred[f'{dof}_pred'][450:]),\n",
    "        #'LSTM_RMSE': np.sqrt(mean_squared_error(y_true_val, LSTM_Tp6p8s_Hs2m_pred[f'{dof}_pred'][450:])),\n",
    "    }\n",
    "\n",
    "# Convert to DataFrame for display\n",
    "metrics_df = pd.DataFrame(metrics).T\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f52bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DoFs and corresponding y-axis units\n",
    "dofs = ['heave', 'pitch', 'pendulum']\n",
    "y_units = {\n",
    "    'heave': 'm',\n",
    "    'pitch': '°',\n",
    "    'pendulum': '°'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Loop through each DoF\n",
    "for dof in dofs:\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Ground Truth (solid black)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=LSTM_Tp6p8s_Hs2m_true[dof],\n",
    "        mode='lines',\n",
    "        name=f'{dof.capitalize()} - Ground Truth',\n",
    "        line=dict(color='black', dash='solid')\n",
    "    ))\n",
    "\n",
    "    # ARX Prediction (dashed blue)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=arx_preds_test[dof],\n",
    "        mode='lines',\n",
    "        name='ARX Prediction',\n",
    "        line=dict(color='blue', dash='dash')\n",
    "    ))\n",
    "\n",
    "    # XGBoost Prediction (dashed red)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=XGB_Tp6p8s_Hs2m_pred_adjusted[dof],\n",
    "        mode='lines',\n",
    "        name='XGBoost-NARX Prediction',\n",
    "        line=dict(color='red', dash='dash')\n",
    "    ))\n",
    "\n",
    "    # LSTM Prediction (dashed green)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=LSTM_Tp6p8s_Hs2m_pred[f'{dof}_pred'],\n",
    "        mode='lines',\n",
    "        name='LSTM Prediction',\n",
    "        line=dict(color='green', dash='dash')\n",
    "    ))\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        title=f'Testing Data Predictions - {dof.capitalize()}',\n",
    "        xaxis_title='Time Step',\n",
    "        yaxis_title=f'{dof.capitalize()} [{y_units[dof]}]',\n",
    "        template='plotly_white'\n",
    "    )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51988739",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define DoFs and corresponding y-axis units\n",
    "dofs = ['heave', 'pitch', 'pendulum']\n",
    "y_units = {\n",
    "    'heave': 'm',\n",
    "    'pitch': '°',\n",
    "    'pendulum': '°'\n",
    "}\n",
    "\n",
    "\n",
    "# Loop through each DoF\n",
    "for dof in dofs:\n",
    "    truth = LSTM_Tp6p8s_Hs2m_true[dof]\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # ARX Absolute Error (blue)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=np.abs(truth - arx_preds_test[dof]),\n",
    "        mode='lines',\n",
    "        name='ARX Absolute Error',\n",
    "        line=dict(color='blue', dash='solid')\n",
    "    ))\n",
    "\n",
    "    # XGBoost Absolute Error (red)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=np.abs(truth - XGB_Tp6p8s_Hs2m_pred_adjusted[dof]),\n",
    "        mode='lines',\n",
    "        name='XGBoost Absolute Error',\n",
    "        line=dict(color='red', dash='solid')\n",
    "    ))\n",
    "\n",
    "    # LSTM Absolute Error (green)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=np.abs(truth - LSTM_Tp6p8s_Hs2m_pred[f'{dof}_pred']),\n",
    "        mode='lines',\n",
    "        name='LSTM Absolute Error',\n",
    "        line=dict(color='green', dash='solid')\n",
    "    ))\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        title=f'Testing Data Absolute Prediction Error - {dof.capitalize()}',\n",
    "        xaxis_title='Time Step',\n",
    "        yaxis_title=f'Absolute Error [{y_units[dof]}]',\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f4fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DoFs and their units\n",
    "dofs = ['heave', 'pitch', 'pendulum']\n",
    "y_units = {'heave': 'm', 'pitch': '°', 'pendulum': '°'}\n",
    "\n",
    "\n",
    "\n",
    "# Create box plots for each DoF\n",
    "for dof in dofs:\n",
    "    truth = LSTM_Tp6p8s_Hs2m_true[dof]\n",
    "\n",
    "    # Calculate absolute errors\n",
    "    arx_error = np.abs(truth - arx_preds_test[dof])\n",
    "    xgb_error = np.abs(truth - XGB_Tp6p8s_Hs2m_pred_adjusted[dof])\n",
    "    lstm_error = np.abs(truth - LSTM_Tp6p8s_Hs2m_pred[f'{dof}_pred'])\n",
    "\n",
    "    # Create box plot\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Box(\n",
    "        y=arx_error,\n",
    "        name='ARX',\n",
    "        marker_color='blue',\n",
    "        boxmean='sd'\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Box(\n",
    "        y=xgb_error,\n",
    "        name='XGBoost-NARX',\n",
    "        marker_color='red',\n",
    "        boxmean='sd'\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Box(\n",
    "        y=lstm_error,\n",
    "        name='LSTM',\n",
    "        marker_color='green',\n",
    "        boxmean='sd'\n",
    "    ))\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f'Testing Data Absolute Prediction Error - {dof.capitalize()}',\n",
    "        yaxis_title=f'Absolute Error [{y_units[dof]}]',\n",
    "        template='plotly_white',\n",
    "        width=600,     # Width in pixels\n",
    "        height=400,\n",
    "        yaxis=dict(range=y_ranges[dof]),\n",
    "\n",
    "        \n",
    "    )\n",
    "    fig.update_layout(showlegend=False)\n",
    "\n",
    "    fig.write_image(f\"Results/testing plots/{dof}_box.png\")\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17f7144",
   "metadata": {},
   "source": [
    "## Extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4de22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case_pretty_map = {\n",
    "    'T4p5s_Hs1m': 'Tp = 4.5 s, Hs = 1 m',\n",
    "    'T4p5s_Hs2m': 'Tp = 4.5 s, Hs = 2 m',\n",
    "    'Tp6p8s_Hs1m': 'Tp = 6.8 s, Hs = 1 m',\n",
    "    'Tp6p8s_Hs2m': 'Tp = 6.8 s, Hs = 2 m',\n",
    "    'Tp6p8s_Hs4m': 'Tp = 6.8 s, Hs = 4 m',\n",
    "    'Tp6p8s_Hs6m': 'Tp = 6.8 s, Hs = 6 m',\n",
    "    'Tp6p8s_Hs8m': 'Tp = 6.8 s, Hs = 8 m',\n",
    "    'T10p2s_Hs1m': 'Tp = 10.2 s, Hs = 1 m',\n",
    "    'Tp10p2_Hs2m': 'Tp = 10.2 s, Hs = 2 m',\n",
    "    'T10p2s_Hs4m': 'Tp = 10.2 s, Hs = 4 m'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e8a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define DoFs and their y-axis units\n",
    "dofs = ['heave', 'pitch', 'pendulum']\n",
    "y_units = {\n",
    "    'heave': 'm',\n",
    "    'pitch': '°',\n",
    "    'pendulum': '°'\n",
    "}\n",
    "\n",
    "# Test cases to evaluate\n",
    "test_cases = [\n",
    "    \"T10p2s_Hs1m\",\n",
    "    \"T10p2s_Hs4m\",\n",
    "    \"T4p5s_Hs1m\",\n",
    "    \"T4p5s_Hs2m\",\n",
    "    \"Tp10p2_Hs2m\",\n",
    "    \"Tp6p8s_Hs1m\",\n",
    "    \"Tp6p8s_Hs2m\",\n",
    "\n",
    "    \"Tp6p8s_Hs4m\",\n",
    "    \"Tp6p8s_Hs6m\",\n",
    "    \"Tp6p8s_Hs8m\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0736f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all metrics\n",
    "all_metrics = []\n",
    "\n",
    "for case in test_cases:\n",
    "    for dof in dofs:\n",
    "        try:\n",
    "            # Ground truth from LSTM\n",
    "            y_true = globals()[f\"LSTM_{case}_true\"][dof]\n",
    "\n",
    "            # ARX prediction\n",
    "            y_arx = globals()[f\"ARX_{dof}_{case}_pred_adjusted\"]\n",
    "            arx_r2 = r2_score(y_true, y_arx)\n",
    "            arx_rmse = np.sqrt(mean_squared_error(y_true, y_arx))\n",
    "\n",
    "            # XGB prediction\n",
    "            y_xgb = globals()[f\"XGB_{case}_pred_adjusted\"][dof]\n",
    "            xgb_r2 = r2_score(y_true, y_xgb)\n",
    "            xgb_rmse = np.sqrt(mean_squared_error(y_true, y_xgb))\n",
    "\n",
    "            # LSTM prediction\n",
    "            y_lstm = globals()[f\"LSTM_{case}_pred\"][f\"{dof}_pred\"]\n",
    "            lstm_r2 = r2_score(y_true, y_lstm)\n",
    "            lstm_rmse = np.sqrt(mean_squared_error(y_true, y_lstm))\n",
    "\n",
    "            # Store results\n",
    "            all_metrics.append({\n",
    "                \"Case\": case,\n",
    "                \"DoF\": dof,\n",
    "                \"ARX_R2\": arx_r2,\n",
    "                \"ARX_RMSE\": arx_rmse,\n",
    "                \"XGB_R2\": xgb_r2,\n",
    "                \"XGB_RMSE\": xgb_rmse,\n",
    "                \"LSTM_R2\": lstm_r2,\n",
    "                \"LSTM_RMSE\": lstm_rmse\n",
    "            })\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(f\"[Missing] {case} - {dof}: {e}\")\n",
    "        except Exception as ex:\n",
    "            print(f\"[Error] {case} - {dof}: {ex}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "\n",
    "# Display\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe416e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases_ordered = [\n",
    "    \"T4p5s_Hs1m\",\n",
    "    \"T4p5s_Hs2m\",\n",
    "    \n",
    "    \"Tp6p8s_Hs1m\",\n",
    "    \"Tp6p8s_Hs2m\",\n",
    "    \"Tp6p8s_Hs4m\",\n",
    "    \"Tp6p8s_Hs6m\",\n",
    "    \"Tp6p8s_Hs8m\",\n",
    "    \"T10p2s_Hs1m\",\n",
    "    \"Tp10p2_Hs2m\",\n",
    "    \"T10p2s_Hs4m\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2704e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your mapping of case names to pretty labels\n",
    "test_case_pretty_map = {\n",
    "    'T4p5s_Hs1m': 'Tp = 4.5 s, Hs = 1 m',\n",
    "    'T4p5s_Hs2m': 'Tp = 4.5 s, Hs = 2 m',\n",
    "    'Tp6p8s_Hs1m': 'Tp = 6.8 s, Hs = 1 m',\n",
    "    'Tp6p8s_Hs2m': 'Tp = 6.8 s, Hs = 2 m',\n",
    "    'Tp6p8s_Hs4m': 'Tp = 6.8 s, Hs = 4 m',\n",
    "    'Tp6p8s_Hs6m': 'Tp = 6.8 s, Hs = 6 m',\n",
    "    'Tp6p8s_Hs8m': 'Tp = 6.8 s, Hs = 8 m',\n",
    "    'T10p2s_Hs1m': 'Tp = 10.2 s, Hs = 1 m',\n",
    "    'Tp10p2_Hs2m': 'Tp = 10.2 s, Hs = 2 m',\n",
    "    'T10p2s_Hs4m': 'Tp = 10.2 s, Hs = 4 m'\n",
    "}\n",
    "\n",
    "# Pretty x-axis labels\n",
    "pretty_labels = [test_case_pretty_map[case] for case in test_cases_ordered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c3fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    \"T4p5s_Hs1m\",\n",
    "    \"T4p5s_Hs2m\",\n",
    "    \"Tp6p8s_Hs4m\",\n",
    "    \"Tp6p8s_Hs1m\",\n",
    "    \"Tp6p8s_Hs6m\",\n",
    "    \"Tp6p8s_Hs8m\",\n",
    "    \"T10p2s_Hs1m\",\n",
    "    \"Tp10p2_Hs2m\",\n",
    "    \"T10p2s_Hs4m\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff28bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_case = \"Tp6p8s_Hs2m\"\n",
    "\n",
    "# Model settings: color, marker symbol, and line style\n",
    "model_info = {\n",
    "    \"ARX\": {\"color\": \"blue\", \"symbol\": \"x\", \"dash\": \"dash\"},\n",
    "    \"XGB\": {\"color\": \"red\", \"symbol\": \"circle\", \"dash\": \"dot\"},\n",
    "    \"LSTM\": {\"color\": \"green\", \"symbol\": \"square\", \"dash\": \"solid\"},\n",
    "}\n",
    "\n",
    "# Loop through DoFs\n",
    "for dof in dofs:\n",
    "    metric_dof = metrics_df[metrics_df[\"DoF\"] == dof]\n",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=(\"RMSE\", \"R² Score\"))\n",
    "\n",
    "    rmse_unit = \"m\" if dof == \"heave\" else \"°\"\n",
    "\n",
    "    for metric_type, col, title, subplot_col in [\n",
    "        (\"RMSE\", \"_RMSE\", \"RMSE\", 1),\n",
    "        (\"R2\", \"_R2\", \"R² Score\", 2)\n",
    "    ]:\n",
    "        for model, props in model_info.items():\n",
    "            y_vals = []\n",
    "            sizes = []\n",
    "            opacities = []\n",
    "\n",
    "            for case in test_cases_ordered:\n",
    "                val = metric_dof.loc[metric_dof[\"Case\"] == case, f\"{model}_{metric_type}\"]\n",
    "                y_vals.append(val.values[0] if not val.empty else None)\n",
    "\n",
    "                if case == highlight_case:\n",
    "                    sizes.append(8)\n",
    "                else:\n",
    "                    sizes.append(8)\n",
    "\n",
    "\n",
    "            # Main line + markers trace\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=pretty_labels,\n",
    "                y=y_vals,\n",
    "                mode=\"lines+markers\",\n",
    "                name=f\"{'XGBoost-NARX' if model == 'XGB' else model} \",\n",
    "                marker=dict(\n",
    "                    symbol=props[\"symbol\"],\n",
    "                    color=props[\"color\"],\n",
    "                    size=sizes,\n",
    "                    opacity=opacities,\n",
    "                    line=dict(width=2, color=\"rgba(255,255,255,0.4)\")\n",
    "                ),\n",
    "                line=dict(color=props[\"color\"], dash=props[\"dash\"]),\n",
    "                showlegend=(subplot_col == 1)\n",
    "            ), row=1, col=subplot_col)\n",
    "\n",
    "            # Add blue glow for the highlight case only\n",
    "            if highlight_case in test_cases_ordered:\n",
    "                idx = test_cases_ordered.index(highlight_case)\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=[pretty_labels[idx]],\n",
    "                    y=[y_vals[idx]],\n",
    "                    mode='markers',\n",
    "                    showlegend=False,\n",
    "                    marker=dict(\n",
    "                        color=\"rgba(255, 255, 0, 0.4)\", \n",
    "                        size=10,\n",
    "                        symbol=props[\"symbol\"],\n",
    "                        line=dict(width=0)\n",
    "                    )\n",
    "                ), row=1, col=subplot_col)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f\"Model Performance Across Sea States – {dof.capitalize()}\",\n",
    "        template=\"plotly_white\",\n",
    "        height=500\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(title_text=f\"RMSE [{rmse_unit}]\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"R² Score\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"Sea State\", tickangle=-45)\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4a2b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for case in test_cases:\n",
    "    for dof in dofs:\n",
    "        fig = go.Figure()\n",
    "        success = True\n",
    "\n",
    "        # Define variable base names\n",
    "        arx_var = f'ARX_{dof}_{case}_true_adjusted'\n",
    "        xgb_var = f'XGB_{case}_true_adjusted'\n",
    "        lstm_var = f'LSTM_{case}_true'\n",
    "        \n",
    "        arx_pred_var = f'ARX_{dof}_{case}_pred_adjusted'\n",
    "        xgb_pred_var = f'XGB_{case}_pred_adjusted'\n",
    "        lstm_pred_var = f'LSTM_{case}_pred'\n",
    "\n",
    "        try:\n",
    "            # Ground truth from ARX or LSTM or XGB (any source is OK if identical)\n",
    "            truth = globals()[arx_var][dof]\n",
    "\n",
    "            # ARX prediction\n",
    "            arx_pred = globals()[arx_pred_var][dof]\n",
    "            fig.add_trace(go.Scatter(\n",
    "                y=arx_pred,\n",
    "                mode='lines',\n",
    "                name='ARX Prediction',\n",
    "                line=dict(color='blue', dash='dash')\n",
    "            ))\n",
    "\n",
    "            # XGB prediction\n",
    "            xgb_pred = globals()[xgb_pred_var][dof]\n",
    "            fig.add_trace(go.Scatter(\n",
    "                y=xgb_pred,\n",
    "                mode='lines',\n",
    "                name='XGBoost-NARX Prediction',\n",
    "                line=dict(color='red', dash='dash')\n",
    "            ))\n",
    "\n",
    "            # LSTM prediction\n",
    "            lstm_pred = globals()[lstm_pred_var][f'{dof}_pred']\n",
    "            fig.add_trace(go.Scatter(\n",
    "                y=lstm_pred,\n",
    "                mode='lines',\n",
    "                name='LSTM Prediction',\n",
    "                line=dict(color='green', dash='dash')\n",
    "            ))\n",
    "\n",
    "            # Ground Truth\n",
    "            fig.add_trace(go.Scatter(\n",
    "                y=truth,\n",
    "                mode='lines',\n",
    "                name=f'{dof.capitalize()} - Ground Truth',\n",
    "                line=dict(color='black', dash='solid')\n",
    "            ))\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(f\"[Missing] {case} {dof}: {e}\")\n",
    "            success = False\n",
    "\n",
    "        if success:\n",
    "            fig.update_layout(\n",
    "                title=f'Sea State: {test_case_pretty_map.get(case, case)} – DoF: {dof.capitalize()}',\n",
    "                xaxis_title='Time Step',\n",
    "                yaxis_title=f'{dof.capitalize()} [{y_units[dof]}]',\n",
    "                template='plotly_white'\n",
    "            )\n",
    "            fig.show()\n",
    "            fig.write_image(f\"Annex/Testing/original/{case}_{dof}.png\", scale=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189901f2",
   "metadata": {},
   "source": [
    "# uncertnity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7cfceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DoFs\n",
    "dofs = ['heave', 'pitch', 'pendulum']\n",
    "\n",
    "# Initialize metrics dictionary\n",
    "nonconformity_scores = {}\n",
    "\n",
    "for dof in dofs:\n",
    "    y_true_val = Val_truth[dof]\n",
    "\n",
    "    nonconformity_scores[dof] = {\n",
    "        # ARX\n",
    "        'ARX_abs_error':abs(y_true_val - arx_preds_val[dof]),\n",
    "        \n",
    "\n",
    "        # XGBoost\n",
    "        'XGB_abs_error': abs(y_true_val - XGB_val_pred_adjusted[dof]),\n",
    "        \n",
    "        # LSTM,\n",
    "        'LSTM_abs_error': abs(y_true_val - LSTM_val_pred[f'{dof}_pred'])\n",
    "        \n",
    "    }\n",
    "\n",
    "# Convert to DataFrame for display\n",
    "metricnonconformity_scoress_df = pd.DataFrame(nonconformity_scores)\n",
    "metricnonconformity_scoress_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35115d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set confidence level\n",
    "confidence_level = 0.95  \n",
    "\n",
    "# Calculate thresholds\n",
    "thresholds = {}\n",
    "for dof in dofs:\n",
    "    thresholds[dof] = {\n",
    "        'ARX': np.quantile(nonconformity_scores[dof]['ARX_abs_error'], confidence_level),\n",
    "        'XGB': np.quantile(nonconformity_scores[dof]['XGB_abs_error'], confidence_level),\n",
    "        'LSTM': np.quantile(nonconformity_scores[dof]['LSTM_abs_error'], confidence_level)\n",
    "    }\n",
    "\n",
    "# Display thresholds\n",
    "thresholds_df_95 = pd.DataFrame(thresholds)\n",
    "print(\"95% Confidence Level Thresholds:\")\n",
    "print(thresholds_df_95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795516ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set confidence level\n",
    "confidence_level = 0.99  \n",
    "\n",
    "# Calculate thresholds\n",
    "thresholds_99 = {}\n",
    "for dof in dofs:\n",
    "    thresholds_99[dof] = {\n",
    "        'ARX': np.quantile(nonconformity_scores[dof]['ARX_abs_error'], confidence_level),\n",
    "        'XGB': np.quantile(nonconformity_scores[dof]['XGB_abs_error'], confidence_level),\n",
    "        'LSTM': np.quantile(nonconformity_scores[dof]['LSTM_abs_error'], confidence_level)\n",
    "    }\n",
    "\n",
    "# Display thresholds\n",
    "thresholds_df_99 = pd.DataFrame(thresholds_99)\n",
    "print(\"99% Confidence Level Thresholds:\")\n",
    "print(thresholds_df_99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a5aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_intervals_95 = {}\n",
    "\n",
    "for dof in dofs:\n",
    "    prediction_intervals_95[dof] = {}\n",
    "    \n",
    "    # Get test predictions \n",
    "    arx_test_pred = arx_preds_test[dof]  #  ARX test predictions\n",
    "    xgb_test_pred = XGB_Tp6p8s_Hs2m_pred_adjusted[dof]  #  XGBoost test predictions  \n",
    "    lstm_test_pred = LSTM_Tp6p8s_Hs2m_pred[f'{dof}_pred']  #  LSTM test predictions\n",
    "    \n",
    "    # Calculate prediction intervals\n",
    "    prediction_intervals_95[dof]['ARX'] = {\n",
    "        'lower': arx_test_pred - thresholds_df_95[dof]['ARX'],\n",
    "        'upper': arx_test_pred + thresholds_df_95[dof]['ARX'],\n",
    "        'prediction': arx_test_pred\n",
    "    }\n",
    "    \n",
    "    prediction_intervals_95[dof]['XGB'] = {\n",
    "        'lower': xgb_test_pred - thresholds_df_95[dof]['XGB'],\n",
    "        'upper': xgb_test_pred + thresholds_df_95[dof]['XGB'],\n",
    "        'prediction': xgb_test_pred\n",
    "    }\n",
    "    \n",
    "    prediction_intervals_95[dof]['LSTM'] = {\n",
    "        'lower': lstm_test_pred - thresholds_df_95[dof]['LSTM'],\n",
    "        'upper': lstm_test_pred + thresholds_df_95[dof]['LSTM'],\n",
    "        'prediction': lstm_test_pred\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179b0f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction_intervals_99 = {}\n",
    "\n",
    "for dof in dofs:\n",
    "    prediction_intervals_99[dof] = {}\n",
    "    \n",
    "    # Get test predictions \n",
    "    arx_test_pred = arx_preds_test[dof]  #  ARX test predictions\n",
    "    xgb_test_pred = XGB_Tp6p8s_Hs2m_pred_adjusted[dof]  #  XGBoost test predictions  \n",
    "    lstm_test_pred = LSTM_Tp6p8s_Hs2m_pred[f'{dof}_pred']  #  LSTM test predictions\n",
    "    \n",
    "    # Calculate prediction intervals\n",
    "    prediction_intervals_99[dof]['ARX'] = {\n",
    "        'lower': arx_test_pred - thresholds_df_99[dof]['ARX'],\n",
    "        'upper': arx_test_pred + thresholds_df_99[dof]['ARX'],\n",
    "        'prediction': arx_test_pred\n",
    "    }\n",
    "    \n",
    "    prediction_intervals_99[dof]['XGB'] = {\n",
    "        'lower': xgb_test_pred - thresholds_df_99[dof]['XGB'],\n",
    "        'upper': xgb_test_pred + thresholds_df_99[dof]['XGB'],\n",
    "        'prediction': xgb_test_pred\n",
    "    }\n",
    "    \n",
    "    prediction_intervals_99[dof]['LSTM'] = {\n",
    "        'lower': lstm_test_pred - thresholds_df_99[dof]['LSTM'],\n",
    "        'upper': lstm_test_pred + thresholds_df_99[dof]['LSTM'],\n",
    "        'prediction': lstm_test_pred\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a65d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_intervals = {}\n",
    "\n",
    "for dof in dofs:\n",
    "    prediction_intervals[dof] = {}\n",
    "    \n",
    "    # Get test predictions \n",
    "    arx_test_pred = arx_preds_test[dof]  #  ARX test predictions\n",
    "    xgb_test_pred = XGB_Tp6p8s_Hs2m_pred_adjusted[dof]  #  XGBoost test predictions  \n",
    "    lstm_test_pred = LSTM_Tp6p8s_Hs2m_pred[f'{dof}_pred']  #  LSTM test predictions\n",
    "    \n",
    "    # Calculate prediction intervals\n",
    "    prediction_intervals[dof]['ARX'] = {\n",
    "        'lower': arx_test_pred - thresholds_df_99[dof]['ARX'],\n",
    "        'upper': arx_test_pred + thresholds_df_99[dof]['ARX'],\n",
    "        'prediction': arx_test_pred\n",
    "    }\n",
    "    \n",
    "    prediction_intervals[dof]['XGB'] = {\n",
    "        'lower': xgb_test_pred - thresholds_df_99[dof]['XGB'],\n",
    "        'upper': xgb_test_pred + thresholds_df_99[dof]['XGB'],\n",
    "        'prediction': xgb_test_pred\n",
    "    }\n",
    "    \n",
    "    prediction_intervals[dof]['LSTM'] = {\n",
    "        'lower': lstm_test_pred - thresholds_df_99[dof]['LSTM'],\n",
    "        'upper': lstm_test_pred + thresholds_df_99[dof]['LSTM'],\n",
    "        'prediction': lstm_test_pred\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6733aa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define DoFs and corresponding y-axis units\n",
    "dofs = ['heave', 'pitch', 'pendulum']\n",
    "y_units = {\n",
    "    'heave': 'm',\n",
    "    'pitch': '°',\n",
    "    'pendulum': '°'\n",
    "}\n",
    "\n",
    "# Set confidence level for prediction intervals\n",
    "confidence_level = 0.99  \n",
    "\n",
    "# Loop through each DoF\n",
    "for dof in dofs:\n",
    "    # Create subplots for ARX, XGBoost, and LSTM in a single row\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=3,\n",
    "        subplot_titles=[\"ARX\", \"XGBoost-NARX\", \"LSTM\"],\n",
    "        shared_yaxes=True\n",
    "    )\n",
    "\n",
    "    # Add ARX Prediction (dashed blue)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=np.arange(1000),  # First 1000 time steps\n",
    "        y=arx_preds_test[dof][:1000],  # ARX Prediction\n",
    "        mode='lines',\n",
    "        name='ARX ',\n",
    "        line=dict(color='blue', dash='dash')\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    # Add ARX Confidence Interval\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=np.arange(1000),  # First 1000 time steps\n",
    "        y=arx_preds_test[dof][:1000] + thresholds_99[dof]['ARX'],  # Upper bound for ARX\n",
    "        fill=None,\n",
    "        mode='lines',\n",
    "        line=dict(color='blue', dash='dot'),\n",
    "        showlegend=False\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=np.arange(1000),\n",
    "        y=arx_preds_test[dof][:1000] - thresholds_99[dof]['ARX'],  # Lower bound for ARX\n",
    "        fill='tonexty',\n",
    "        mode='lines',\n",
    "        line=dict(color='blue', dash='dot'),\n",
    "        name='ARX Confidence Interval (99%)',\n",
    "        fillcolor='rgba(0, 0, 255, 0.2)',\n",
    "        showlegend=False\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    # Add XGBoost Prediction (dashed red)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=np.arange(1000),  # First 1000 time steps\n",
    "        y=XGB_Tp6p8s_Hs2m_pred_adjusted[dof][:1000],  # XGBoost Prediction\n",
    "        mode='lines',\n",
    "        name='XGBoost-NARX ',\n",
    "        line=dict(color='red', dash='dash')\n",
    "    ), row=1, col=2)\n",
    "\n",
    "    # Add XGBoost Confidence Interval\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=np.arange(1000),  # First 1000 time steps\n",
    "        y=XGB_Tp6p8s_Hs2m_pred_adjusted[dof][:1000] + thresholds_99[dof]['XGB'],  # Upper bound for XGBoost\n",
    "        fill=None,\n",
    "        mode='lines',\n",
    "        line=dict(color='red', dash='dot'),\n",
    "        showlegend=False\n",
    "    ), row=1, col=2)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=np.arange(1000),\n",
    "        y=XGB_Tp6p8s_Hs2m_pred_adjusted[dof][:1000] - thresholds_99[dof]['XGB'],  # Lower bound for XGBoost\n",
    "        fill='tonexty',\n",
    "        mode='lines',\n",
    "        line=dict(color='red', dash='dot'),\n",
    "        name='XGBoost-NARX Confidence Interval (99%)',\n",
    "        fillcolor='rgba(255, 0, 0, 0.2)',\n",
    "        showlegend=False\n",
    "    ), row=1, col=2)\n",
    "\n",
    "    # Add LSTM Prediction (dashed green)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=np.arange(1000),  # First 1000 time steps\n",
    "        y=LSTM_Tp6p8s_Hs2m_pred[f'{dof}_pred'][:1000],  # LSTM Prediction\n",
    "        mode='lines',\n",
    "        name='LSTM ',\n",
    "        line=dict(color='green', dash='dash')\n",
    "    ), row=1, col=3)\n",
    "\n",
    "    # Add LSTM Confidence Interval\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=np.arange(1000),  # First 1000 time steps\n",
    "        y=LSTM_Tp6p8s_Hs2m_pred[f'{dof}_pred'][:1000] + thresholds_99[dof]['LSTM'],  # Upper bound for LSTM\n",
    "        fill=None,\n",
    "        mode='lines',\n",
    "        line=dict(color='green', dash='dot'),\n",
    "        showlegend=False\n",
    "    ), row=1, col=3)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=np.arange(1000),\n",
    "        y=LSTM_Tp6p8s_Hs2m_pred[f'{dof}_pred'][:1000] - thresholds_99[dof]['LSTM'],  # Lower bound for LSTM\n",
    "        fill='tonexty',\n",
    "        mode='lines',\n",
    "        line=dict(color='green', dash='dot'),\n",
    "        name='LSTM Confidence Interval',\n",
    "        fillcolor='rgba(0, 255, 0, 0.2)',\n",
    "        showlegend=False\n",
    "    ), row=1, col=3)\n",
    "\n",
    "    # Ground Truth (solid black) - Same for all models\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=np.arange(1000),  # First 1000 time steps\n",
    "        y=LSTM_Tp6p8s_Hs2m_true[dof][:1000],  # Ground Truth\n",
    "        mode='lines',\n",
    "        name='Ground Truth',\n",
    "        line=dict(color='black', dash='solid')\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=np.arange(1000),\n",
    "        y=LSTM_Tp6p8s_Hs2m_true[dof][:1000],  # Ground Truth\n",
    "        mode='lines',\n",
    "        showlegend=False,\n",
    "        name=f'{dof.capitalize()} - Ground Truth',\n",
    "        line=dict(color='black', dash='solid')\n",
    "    ), row=1, col=2)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=np.arange(1000),\n",
    "        y=LSTM_Tp6p8s_Hs2m_true[dof][:1000],  # Ground Truth\n",
    "        mode='lines',\n",
    "        showlegend=False,\n",
    "        name=f'{dof.capitalize()}Ground Truth',\n",
    "        line=dict(color='black', dash='solid')\n",
    "    ), row=1, col=3)\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        title=f'99% Confidence Intervals for Models Predictions across Testing Data - {dof.capitalize()}',\n",
    "        xaxis_title='Time Step',\n",
    "        yaxis_title=f'{dof.capitalize()} [{y_units[dof]}]',\n",
    "        template='plotly_white',\n",
    "        showlegend=True,\n",
    "        height=400,\n",
    "        width=800\n",
    "    )\n",
    "    \n",
    "    output_dir = \"Results/uncertanity/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    fig.write_image(f\"{output_dir}{dof}_uncertanity.png\")\n",
    "    # Show the figure\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
